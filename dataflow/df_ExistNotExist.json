{
	"name": "df_ExistNotExist",
	"properties": {
		"type": "MappingDataFlow",
		"typeProperties": {
			"sources": [
				{
					"dataset": {
						"referenceName": "EmployeeData",
						"type": "DatasetReference"
					},
					"name": "EmpData"
				},
				{
					"dataset": {
						"referenceName": "DepartmentData",
						"type": "DatasetReference"
					},
					"name": "DepData"
				}
			],
			"sinks": [
				{
					"dataset": {
						"referenceName": "OutPutDataSet",
						"type": "DatasetReference"
					},
					"name": "ExistingData"
				}
			],
			"transformations": [
				{
					"name": "ExistManagerId"
				}
			],
			"scriptLines": [
				"source(output(",
				"          EMPLOYEE_ID as string,",
				"          FIRST_NAME as string,",
				"          LAST_NAME as string,",
				"          EMAIL as string,",
				"          PHONE_NUMBER as string,",
				"          HIRE_DATE as string,",
				"          JOB_ID as string,",
				"          SALARY as string,",
				"          COMMISSION_PCT as string,",
				"          MANAGER_ID as string,",
				"          DEPARTMENT_ID as string",
				"     ),",
				"     allowSchemaDrift: true,",
				"     validateSchema: false,",
				"     ignoreNoFilesFound: false) ~> EmpData",
				"source(output(",
				"          DEPARTMENT_ID as string,",
				"          DEPARTMENT_NAME as string,",
				"          MANAGER_ID as string,",
				"          LOCATION_ID as string",
				"     ),",
				"     allowSchemaDrift: true,",
				"     validateSchema: false,",
				"     ignoreNoFilesFound: false) ~> DepData",
				"EmpData, DepData exists(EmpData@DEPARTMENT_ID == DepData@DEPARTMENT_ID,",
				"     negate:false,",
				"     partitionBy('hash', 1),",
				"     broadcast: 'auto')~> ExistManagerId",
				"ExistManagerId sink(allowSchemaDrift: true,",
				"     validateSchema: false,",
				"     partitionFileNames:['ExistingDataManagerID.csv'],",
				"     skipDuplicateMapInputs: true,",
				"     skipDuplicateMapOutputs: true,",
				"     partitionBy('hash', 1)) ~> ExistingData"
			]
		}
	}
}